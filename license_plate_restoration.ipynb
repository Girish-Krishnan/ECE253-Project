{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# License Plate Restoration\n",
    "\n",
    "Demo notebook for image restoration (fog removal, deblurring, dark enhancement) and license plate OCR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from scipy import ndimage\n",
    "from scipy.signal import convolve2d\n",
    "\n",
    "# kaggle dataset path\n",
    "DATA_DIR = Path('/kaggle/input/adverse-condition-image-restoration-for-lpr')\n",
    "if not DATA_DIR.exists():\n",
    "    DATA_DIR = Path('.')\n",
    "\n",
    "print(f\"Using data dir: {DATA_DIR}\")\n",
    "if DATA_DIR.exists():\n",
    "    files = list(DATA_DIR.glob('*'))[:10]\n",
    "    print(f\"Found {len(files)} items\")\n",
    "    for f in files[:5]:\n",
    "        print(f\"  {f.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distortion classification\n",
    "BRIGHT_DARK_THRESH = 80\n",
    "BLUR_LAP_VAR_THRESH = 60\n",
    "FOG_BRIGHT_THRESH = 150\n",
    "FOG_CONTRAST_MAX = 40\n",
    "\n",
    "def classify_distortion(img_bgr):\n",
    "    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    brightness = float(gray.mean())\n",
    "    contrast = float(gray.std())\n",
    "    lap = cv2.Laplacian(gray, cv2.CV_64F)\n",
    "    lap_var = float(lap.var())\n",
    "    \n",
    "    classes = []\n",
    "    if brightness < BRIGHT_DARK_THRESH:\n",
    "        classes.append(\"dark\")\n",
    "    if lap_var < BLUR_LAP_VAR_THRESH:\n",
    "        classes.append(\"blur\")\n",
    "    if brightness > FOG_BRIGHT_THRESH and contrast < FOG_CONTRAST_MAX:\n",
    "        classes.append(\"fog\")\n",
    "    if not classes:\n",
    "        classes.append(\"clean\")\n",
    "    return classes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fog removal (dark channel prior + CLAHE)\n",
    "def defog_dcp_clahe(image_bgr):\n",
    "    I = image_bgr.astype(np.float32) / 255.0\n",
    "    patch = 5\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (patch, patch))\n",
    "    dark = cv2.erode(np.min(I, axis=2), kernel)\n",
    "    \n",
    "    num_pixels = I.shape[0] * I.shape[1]\n",
    "    top_k = max(1, num_pixels // 2000)\n",
    "    indices = np.argpartition(dark.flatten(), -top_k)[-top_k:]\n",
    "    A = np.mean(I.reshape(-1,3)[indices], axis=0)\n",
    "    \n",
    "    omega = 0.75\n",
    "    norm_I = I / (A + 1e-6)\n",
    "    dark_norm = cv2.erode(np.min(norm_I, axis=2), kernel)\n",
    "    t = 1 - omega * dark_norm\n",
    "    t0 = 0.2\n",
    "    t = np.clip(t, t0, 1)\n",
    "    t = cv2.GaussianBlur(t, (7,7), 10)\n",
    "    \n",
    "    J = (I - A) / t[..., None] + A\n",
    "    J = np.clip(J, 0, 1)\n",
    "    \n",
    "    blend_alpha = 0.8\n",
    "    J = blend_alpha * J + (1 - blend_alpha) * I\n",
    "    \n",
    "    hsv = cv2.cvtColor((J*255).astype(np.uint8), cv2.COLOR_BGR2HSV)\n",
    "    clahe = cv2.createCLAHE(clipLimit=0.8, tileGridSize=(8,8))\n",
    "    hsv[:,:,2] = clahe.apply(hsv[:,:,2])\n",
    "    out = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dark enhancement (IAGCWD)\n",
    "def image_agcwd(img, a=0.25, truncated_cdf=False):\n",
    "    hist, bins = np.histogram(img.flatten(), 256, [0, 256])\n",
    "    cdf = hist.cumsum()\n",
    "    cdf_normalized = cdf / cdf.max()\n",
    "    prob_normalized = hist / hist.sum()\n",
    "    \n",
    "    unique_intensity = np.unique(img)\n",
    "    prob_min = prob_normalized.min()\n",
    "    prob_max = prob_normalized.max()\n",
    "    \n",
    "    pn_temp = (prob_normalized - prob_min) / (prob_max - prob_min + 1e-10)\n",
    "    pn_temp[pn_temp>0] = prob_max * (pn_temp[pn_temp>0]**a)\n",
    "    pn_temp[pn_temp<0] = prob_max * (-((-pn_temp[pn_temp<0])**a))\n",
    "    prob_normalized_wd = pn_temp / (pn_temp.sum() + 1e-10)\n",
    "    cdf_prob_normalized_wd = prob_normalized_wd.cumsum()\n",
    "    \n",
    "    if truncated_cdf:\n",
    "        inverse_cdf = np.maximum(0.5, 1 - cdf_prob_normalized_wd)\n",
    "    else:\n",
    "        inverse_cdf = 1 - cdf_prob_normalized_wd\n",
    "    \n",
    "    img_new = img.copy()\n",
    "    for i in unique_intensity:\n",
    "        img_new[img==i] = np.round(255 * (i / 255)**inverse_cdf[i])\n",
    "    return img_new\n",
    "\n",
    "def process_dimmed(img):\n",
    "    return image_agcwd(img, a=0.75, truncated_cdf=True)\n",
    "\n",
    "def enhance_dark(image_bgr):\n",
    "    YCrCb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2YCrCb)\n",
    "    Y = YCrCb[:,:,0]\n",
    "    threshold = 0.3\n",
    "    exp_in = 112\n",
    "    M, N = image_bgr.shape[:2]\n",
    "    mean_in = np.sum(Y / (M * N))\n",
    "    t = (mean_in - exp_in) / exp_in\n",
    "    \n",
    "    if t < -threshold:\n",
    "        result = process_dimmed(Y)\n",
    "        YCrCb[:,:,0] = result\n",
    "        return cv2.cvtColor(YCrCb, cv2.COLOR_YCrCb2BGR)\n",
    "    else:\n",
    "        return image_bgr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# motion deblur (Richardson-Lucy)\n",
    "def create_motion_psf(length, angle, size=31):\n",
    "    kernel = np.zeros((size, size), dtype=np.float32)\n",
    "    center = size // 2\n",
    "    angle_rad = np.deg2rad(angle)\n",
    "    for i in range(length):\n",
    "        x = int(center + (i - length/2) * np.cos(angle_rad))\n",
    "        y = int(center + (i - length/2) * np.sin(angle_rad))\n",
    "        if 0 <= x < size and 0 <= y < size:\n",
    "            kernel[y, x] = 1.0\n",
    "    if kernel.sum() > 0:\n",
    "        kernel /= kernel.sum()\n",
    "    return kernel\n",
    "\n",
    "def richardson_lucy_deconv(image, psf, num_iter=20, sigma=0.5):\n",
    "    estimate = image.copy()\n",
    "    psf_flipped = np.flip(np.flip(psf, 0), 1)\n",
    "    eps = 1e-10\n",
    "    \n",
    "    for _ in range(num_iter):\n",
    "        blurred_estimate = convolve2d(estimate, psf, mode='same', boundary='symm')\n",
    "        ratio = image / (blurred_estimate + eps)\n",
    "        ratio = np.clip(ratio, 0.01, 0.99)\n",
    "        correction = convolve2d(ratio, psf_flipped, mode='same', boundary='symm')\n",
    "        estimate = estimate * correction\n",
    "        if sigma > 0:\n",
    "            estimate = ndimage.gaussian_filter(estimate, sigma=sigma)\n",
    "        estimate = np.clip(estimate, 0, 1)\n",
    "    return estimate\n",
    "\n",
    "def deblur_image(image_bgr):\n",
    "    h, w = image_bgr.shape[:2]\n",
    "    scale = 0.5 if max(h, w) > 800 else 1.0\n",
    "    if scale < 1.0:\n",
    "        img_small = cv2.resize(image_bgr, (int(w*scale), int(h*scale)))\n",
    "    else:\n",
    "        img_small = image_bgr\n",
    "    \n",
    "    img_gray = cv2.cvtColor(img_small, cv2.COLOR_BGR2GRAY).astype(np.float32) / 255.0\n",
    "    \n",
    "    lengths = [10, 20, 30]\n",
    "    angles = [0, 45, 90]\n",
    "    best_kernel = None\n",
    "    best_score = -1\n",
    "    \n",
    "    for length in lengths:\n",
    "        for angle in angles:\n",
    "            psf = create_motion_psf(length, angle, size=31)\n",
    "            if psf.sum() == 0:\n",
    "                continue\n",
    "            estimate = richardson_lucy_deconv(img_gray, psf, num_iter=5, sigma=0.5)\n",
    "            laplacian = cv2.Laplacian((estimate * 255).astype(np.uint8), cv2.CV_64F)\n",
    "            score = laplacian.var()\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_kernel = (length, angle, psf)\n",
    "    \n",
    "    if best_kernel is None:\n",
    "        return image_bgr\n",
    "    \n",
    "    length, angle, psf = best_kernel\n",
    "    img_gray_full = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY).astype(np.float32) / 255.0\n",
    "    deblurred_gray = richardson_lucy_deconv(img_gray_full, psf, num_iter=20, sigma=0.5)\n",
    "    deblurred_gray_uint8 = (np.clip(deblurred_gray, 0, 1) * 255).astype(np.uint8)\n",
    "    return cv2.cvtColor(deblurred_gray_uint8, cv2.COLOR_GRAY2BGR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find images\n",
    "image_files = []\n",
    "for ext in ['.jpg', '.jpeg', '.png', '.bmp']:\n",
    "    image_files.extend(list(DATA_DIR.rglob(f'*{ext}')))\n",
    "    image_files.extend(list(DATA_DIR.rglob(f'*{ext.upper()}')))\n",
    "\n",
    "print(f\"Found {len(image_files)} images\")\n",
    "if len(image_files) == 0:\n",
    "    print(\"No images found, using test image if available\")\n",
    "    test_img = cv2.imread('test.jpg')\n",
    "    if test_img is not None:\n",
    "        print(\"Using test.jpg\")\n",
    "        image_files = [Path('test.jpg')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process first few images\n",
    "def process_image(img_path):\n",
    "    img = cv2.imread(str(img_path))\n",
    "    if img is None:\n",
    "        return None, None, None, None\n",
    "    \n",
    "    # classify distortion\n",
    "    dist_type = classify_distortion(img)\n",
    "    \n",
    "    # apply restoration\n",
    "    restored = img.copy()\n",
    "    if dist_type == 'fog':\n",
    "        restored = defog_dcp_clahe(img)\n",
    "    elif dist_type == 'dark':\n",
    "        restored = enhance_dark(img)\n",
    "    elif dist_type == 'blur':\n",
    "        restored = deblur_image(img)\n",
    "    \n",
    "    return img, restored, dist_type, img_path.name\n",
    "\n",
    "# process up to 5 images\n",
    "results = []\n",
    "for img_path in image_files[:5]:\n",
    "    original, restored, dist_type, name = process_image(img_path)\n",
    "    if original is not None:\n",
    "        results.append((original, restored, dist_type, name))\n",
    "        print(f\"Processed {name}: {dist_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display results\n",
    "def show_comparison(original, restored, title, dist_type):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    orig_rgb = cv2.cvtColor(original, cv2.COLOR_BGR2RGB)\n",
    "    rest_rgb = cv2.cvtColor(restored, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    axes[0].imshow(orig_rgb)\n",
    "    axes[0].set_title(f\"Original ({dist_type})\")\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(rest_rgb)\n",
    "    axes[1].set_title(\"Restored\")\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    plt.suptitle(title, fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "for original, restored, dist_type, name in results:\n",
    "    show_comparison(original, restored, name, dist_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## License Plate OCR\n",
    "\n",
    "Note: This requires fast-alpr to be installed. For Kaggle, you may need to install it first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to run OCR (will fail gracefully if not available)\n",
    "try:\n",
    "    from fast_alpr import ALPR\n",
    "    \n",
    "    alpr = ALPR(\n",
    "        detector_model=\"yolo-v9-t-384-license-plate-end2end\",\n",
    "        ocr_model=\"cct-xs-v1-global-model\",\n",
    "    )\n",
    "    \n",
    "    def run_ocr(img_bgr):\n",
    "        detections = alpr.detector.predict(img_bgr)\n",
    "        if not detections:\n",
    "            return \"\"\n",
    "        best = max(detections, key=lambda d: d.confidence)\n",
    "        bbox = best.bounding_box\n",
    "        x1, y1 = max(bbox.x1, 0), max(bbox.y1, 0)\n",
    "        x2, y2 = min(bbox.x2, img_bgr.shape[1]), min(bbox.y2, img_bgr.shape[0])\n",
    "        cropped = img_bgr[y1:y2, x1:x2]\n",
    "        ocr_result = alpr.ocr.predict(cropped)\n",
    "        return ocr_result.text if ocr_result and ocr_result.text else \"\"\n",
    "    \n",
    "    print(\"OCR available!\")\n",
    "    \n",
    "    # run OCR on restored images\n",
    "    for original, restored, dist_type, name in results:\n",
    "        orig_text = run_ocr(original)\n",
    "        rest_text = run_ocr(restored)\n",
    "        print(f\"\\n{name} ({dist_type}):\")\n",
    "        print(f\"  Original: {orig_text if orig_text else 'No plate detected'}\")\n",
    "        print(f\"  Restored: {rest_text if rest_text else 'No plate detected'}\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"fast-alpr not available. Install with: pip install fast-alpr\")\n",
    "except Exception as e:\n",
    "    print(f\"OCR error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
